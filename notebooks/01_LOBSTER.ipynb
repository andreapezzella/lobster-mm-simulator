{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f502a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Constants (LOBSTER)\n",
    "levels = 10\n",
    "PRICE_SCALE = 10000.0\n",
    "ASK_DUMMY = 9999999999\n",
    "BID_DUMMY = -9999999999\n",
    "\n",
    "\n",
    "def load_lobster(\n",
    "    message_path: Path,\n",
    "    orderbook_path: Path,\n",
    "    levels: int = 10,\n",
    "    price_scale: float = PRICE_SCALE,\n",
    "    set_time_index: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load LOBSTER message + orderbook files and return a single DataFrame.\n",
    "\n",
    "    - Prices are kept in raw integer units (as in LOBSTER).\n",
    "    - Dummy prices are replaced with NaN (only for price columns).\n",
    "    - Adds top-of-book dollar columns (ask_p1_d, bid_p1_d), spread and mid (in dollars).\n",
    "    \"\"\"\n",
    "\n",
    "    # Read message file\n",
    "    msg_cols = [\"time\", \"type\", \"order_id\", \"size\", \"price\", \"direction\"]\n",
    "    msg = pd.read_csv(\n",
    "        message_path,\n",
    "        header=None,\n",
    "        names=msg_cols,\n",
    "        dtype={\n",
    "            \"type\": \"int16\",\n",
    "            \"order_id\": \"int64\",\n",
    "            \"size\": \"int32\",\n",
    "            \"price\": \"int64\",\n",
    "            \"direction\": \"int8\",\n",
    "        },\n",
    "    )\n",
    "    msg[\"time\"] = msg[\"time\"].astype(\"float64\")\n",
    "\n",
    "    # Sanity check #1\n",
    "    if not msg[\"time\"].is_monotonic_increasing:\n",
    "        raise ValueError(\"Message times are not monotonic increasing. Check input files.\")\n",
    "\n",
    "    # Read orderbook file\n",
    "    ob_cols: list[str] = []\n",
    "    for lvl in range(1, levels + 1):\n",
    "        ob_cols += [f\"ask_p{lvl}\", f\"ask_s{lvl}\", f\"bid_p{lvl}\", f\"bid_s{lvl}\"]\n",
    "\n",
    "    ob = pd.read_csv(\n",
    "        orderbook_path,\n",
    "        header=None,\n",
    "        names=ob_cols,\n",
    "        usecols=list(range(4 * levels)),\n",
    "    )\n",
    "\n",
    "    # Set dtypes explicitly (prices int64, sizes int32)\n",
    "    for c in ob_cols:\n",
    "        ob[c] = ob[c].astype(\"int64\" if \"_p\" in c else \"int32\")\n",
    "\n",
    "    # Sanity check #2: message rows must match orderbook rows\n",
    "    if len(msg) != len(ob):\n",
    "        raise ValueError(f\"Row mismatch: msg={len(msg)} vs ob={len(ob)}\")\n",
    "\n",
    "    #  Combine\n",
    "    df = pd.concat([msg.reset_index(drop=True), ob.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Keep time as a column; optionally also use it as index (index can have duplicates)\n",
    "    df = df.sort_values(\"time\", kind=\"mergesort\")  # stable sort\n",
    "    if set_time_index:\n",
    "        df = df.set_index(\"time\", drop=False)\n",
    "\n",
    "    # Dummy handling (price columns only)\n",
    "    ask_price_cols = [f\"ask_p{i}\" for i in range(1, levels + 1)]\n",
    "    bid_price_cols = [f\"bid_p{i}\" for i in range(1, levels + 1)]\n",
    "\n",
    "    dummy_before = (\n",
    "        (df[ask_price_cols] == ASK_DUMMY).sum().sum()\n",
    "        + (df[bid_price_cols] == BID_DUMMY).sum().sum()\n",
    "    )\n",
    "\n",
    "    for col in ask_price_cols:\n",
    "        df.loc[df[col] == ASK_DUMMY, col] = np.nan\n",
    "    for col in bid_price_cols:\n",
    "        df.loc[df[col] == BID_DUMMY, col] = np.nan\n",
    "\n",
    "    dummy_after = (\n",
    "        (df[ask_price_cols] == ASK_DUMMY).sum().sum()\n",
    "        + (df[bid_price_cols] == BID_DUMMY).sum().sum()\n",
    "    )\n",
    "\n",
    "    if dummy_after != 0:\n",
    "        raise ValueError(\"Dummy replacement failed: some dummy prices are still present.\")\n",
    "\n",
    "    # Top-of-book derived fields (dollars)\n",
    "    df[\"ask_p1_d\"] = df[\"ask_p1\"] / price_scale\n",
    "    df[\"bid_p1_d\"] = df[\"bid_p1\"] / price_scale\n",
    "\n",
    "    # spread & mid only where both sides exist\n",
    "    valid_top = df[\"ask_p1\"].notna() & df[\"bid_p1\"].notna()\n",
    "    df[\"spread\"] = np.nan\n",
    "    df[\"mid\"] = np.nan\n",
    "    df.loc[valid_top, \"spread\"] = (df.loc[valid_top, \"ask_p1\"] - df.loc[valid_top, \"bid_p1\"]) / price_scale\n",
    "    df.loc[valid_top, \"mid\"] = (df.loc[valid_top, \"ask_p1\"] + df.loc[valid_top, \"bid_p1\"]) / (2 * price_scale)\n",
    "\n",
    "    # Sanity check #3: spread should be >= 0 almost always (allow tiny tolerance)\n",
    "    neg_share = (df.loc[valid_top, \"spread\"] < 0).mean()\n",
    "    if neg_share > 1e-6:\n",
    "        nneg = int((df.loc[valid_top, \"spread\"] < 0).sum())\n",
    "        raise ValueError(f\"Negative spread found in {nneg} rows ({neg_share:.2e} share).\")\n",
    "\n",
    "    # Lightweight info (helps debugging, not too verbose)\n",
    "    print(f\"Loaded: {message_path.name}\")\n",
    "    print(f\"Rows: {len(df):,} | Dummy prices replaced: {int(dummy_before):,} | Negative-spread share: {neg_share:.2e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_processed(df: pd.DataFrame, out_path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Save processed dataset. Tries Parquet first; falls back to pickle if Parquet engine is missing.\n",
    "    \"\"\"\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        df.to_parquet(out_path, index=True)\n",
    "        print(f\"Saved parquet -> {out_path}\")\n",
    "    except Exception as e:\n",
    "        fallback = out_path.with_suffix(\".pkl\")\n",
    "        df.to_pickle(fallback)\n",
    "        print(f\"Parquet failed ({type(e).__name__}). Saved pickle -> {fallback}\")\n",
    "\n",
    "\n",
    "# Usage (adjust paths to your repo layout)\n",
    "DATA_DIR = Path(\"..\") / \"Data\"         # or: Path(\"..\") / \"data\" / \"raw\"\n",
    "PROCESSED_DIR = Path(\"..\") / \"data\" / \"processed\"\n",
    "\n",
    "message_path = next(DATA_DIR.glob(\"*_message_10.csv\"))\n",
    "orderbook_path = next(DATA_DIR.glob(\"*_orderbook_10.csv\"))\n",
    "\n",
    "df = load_lobster(message_path, orderbook_path, levels=10, set_time_index=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1047d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Persist (optional) ---\n",
    "# Uncomment to save a processed dataset for faster downstream notebooks\n",
    "# save_processed(df, PROCESSED_DIR / \"goog_2012-06-21.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0da8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick integrity checks\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Time range:\", df[\"time\"].min(), \"->\", df[\"time\"].max())\n",
    "\n",
    "# Top-of-book availability\n",
    "valid_top = df[\"ask_p1\"].notna() & df[\"bid_p1\"].notna()\n",
    "print(\"Top-of-book available:\", f\"{valid_top.mean():.4%}\")\n",
    "\n",
    "# Spread sanity\n",
    "print(\"Spread < 0 count:\", int((df.loc[valid_top, \"spread\"] < 0).sum()))\n",
    "print(\"Spread == 0 count:\", int((df.loc[valid_top, \"spread\"] == 0).sum()))\n",
    "\n",
    "df[[\"ask_p1_d\", \"bid_p1_d\", \"spread\", \"mid\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing levels due to dummy\n",
    "ask_price_cols = [f\"ask_p{i}\" for i in range(1, levels + 1)]\n",
    "bid_price_cols = [f\"bid_p{i}\" for i in range(1, levels + 1)]\n",
    "\n",
    "print(\"NaN share (ask prices) by level:\")\n",
    "print((df[ask_price_cols].isna().mean()).to_string())\n",
    "\n",
    "print(\"\\nNaN share (bid prices) by level:\")\n",
    "print((df[bid_price_cols].isna().mean()).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Spread over time\n",
    "sample = df.loc[df[\"spread\"].notna(), [\"time\", \"spread\"]].iloc[::200]\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(sample[\"time\"], sample[\"spread\"], linewidth=1)\n",
    "ax.set_title(\"LOBSTER â€” Spread over time\")\n",
    "ax.set_xlabel(\"Time (seconds)\")\n",
    "ax.set_ylabel(\"Spread ($)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d13d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anna5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
